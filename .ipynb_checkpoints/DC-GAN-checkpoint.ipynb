{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebcca47-a12f-4477-af9c-25224d538678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import ignite\n",
    "import os\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from ignite.engine import Engine, Events\n",
    "import ignite.distributed as idist\n",
    "from ignite.metrics import FID, InceptionScore\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "\n",
    "ignite.utils.manual_seed(999)\n",
    "\n",
    "ignite.utils.setup_logger(name=\"ignite.distributed.auto.auto_dataloader\", level=logging.WARNING)\n",
    "ignite.utils.setup_logger(name=\"ignite.distributed.launcher.Parallel\", level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec0fa94-0971-4d75-bd58-86501f148fcf",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f878ef1-9351-4ae7-93a0-c73de8294de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 64\n",
    "\n",
    "data_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = ImageFolder(root=\"./multi_classifier_data/MultiClassifier/\", transform=data_transform)\n",
    "test_dataset = torch.utils.data.Subset(train_dataset, torch.arange(3000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26531aba-f492-42f0-adcc-060f3bc66c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_dataloader = idist.auto_dataloader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    num_workers=2, \n",
    "    shuffle=True, \n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "test_dataloader = idist.auto_dataloader(\n",
    "    test_dataset, \n",
    "    batch_size=batch_size, \n",
    "    num_workers=2, \n",
    "    shuffle=False, \n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fb3c1e-7e1a-426a-ba5b-e57b71f856f5",
   "metadata": {},
   "source": [
    "Let's explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ebfa1d-c00b-4541-94e0-5c21aa16819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_batch = next(iter(train_dataloader))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0][:64], padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b1efa3-05c3-4fb1-b45c-aac194110c53",
   "metadata": {},
   "source": [
    "# DC-GAN Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d9cfd3-f9f9-4172-8e52-ab2f86334ded",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edca3663-0d1b-4538-8c6b-cfecb1a0b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator3x64x64(nn.Module):\n",
    "    def __init__(self, latent_dim=100):\n",
    "        super(Generator3x64x64, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dim, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            # state size. 512 x 4 x 4\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            # state size. 256 x 8 x 8\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            # state size. 128 x 16 x 16\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            # state size. 64 x 32 x 32\n",
    "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # final state size. 3 x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9aba3d-dba7-434f-9313-c99b9dcfdb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Generator into idist\n",
    "netG = idist.auto_model(Generator3x64x64())\n",
    "\n",
    "# Move the model into the CPU/GPU chosen training device\n",
    "idist.device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81723667-ee5a-4c2c-b68d-306db6d610c3",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcbfa9f-744c-4e0b-bf3d-6a69aa6447da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator3x64x64(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator3x64x64, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # input is 3 x 64 x 64\n",
    "            nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. 64 x 32 x 32\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. 128 x 16 x 16\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. 256 x 8 x 8\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. 512 x 4 x 4\n",
    "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d751cb9-8652-4ea9-88a0-592f6e23a87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "netD = idist.auto_model(Discriminator3x64x64())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ef26bd-e85e-4de9-baf1-79181cc4f232",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b686e4-5d38-45f2-ab6f-ff438a863c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Noise for generating training progress images in the generator\n",
    "fixed_noise = torch.randn(64, 100, 1, 1, device=idist.device())\n",
    "\n",
    "# Different optimizer options for generator and discriminator\n",
    "optimizerD = idist.auto_optim(\n",
    "    optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    ")\n",
    "\n",
    "optimizerG = idist.auto_optim(\n",
    "    optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48fa6ce-1080-4726-891b-4e732463ac23",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2441887-beb6-4918-adb8-f3c8ac0eed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_step function for Pytorch Ignite\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "\n",
    "def training_step(engine, data):\n",
    "    # Set the models for training\n",
    "    netG.train()\n",
    "    netD.train()\n",
    "\n",
    "    ############################\n",
    "    # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "    ###########################\n",
    "    ## Train with all-real batch\n",
    "    netD.zero_grad()\n",
    "    # Format batch\n",
    "    real = data[0].to(idist.device())\n",
    "    b_size = real.size(0)\n",
    "    label = torch.full((b_size,), real_label, dtype=torch.float, device=idist.device())\n",
    "    # Forward pass real batch through D\n",
    "    output1 = netD(real).view(-1)\n",
    "    # Calculate loss on all-real batch\n",
    "    errD_real = criterion(output1, label)\n",
    "    # Calculate gradients for D in backward pass\n",
    "    errD_real.backward()\n",
    "\n",
    "    ## Train with all-fake batch\n",
    "    # Generate batch of latent vectors\n",
    "    noise = torch.randn(b_size, latent_dim, 1, 1, device=idist.device())\n",
    "    # Generate fake image batch with G\n",
    "    fake = netG(noise)\n",
    "    label.fill_(fake_label)\n",
    "    # Classify all fake batch with D\n",
    "    output2 = netD(fake.detach()).view(-1)\n",
    "    # Calculate D's loss on the all-fake batch\n",
    "    errD_fake = criterion(output2, label)\n",
    "    # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "    errD_fake.backward()\n",
    "    # Compute error of D as sum over the fake and the real batches\n",
    "    errD = errD_real + errD_fake\n",
    "    # Update D\n",
    "    optimizerD.step()\n",
    "\n",
    "    ############################\n",
    "    # (2) Update G network: maximize log(D(G(z)))\n",
    "    ###########################\n",
    "    netG.zero_grad()\n",
    "    label.fill_(real_label)  # fake labels are real for generator cost\n",
    "    # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "    output3 = netD(fake).view(-1)\n",
    "    # Calculate G's loss based on this output\n",
    "    errG = criterion(output3, label)\n",
    "    # Calculate gradients for G\n",
    "    errG.backward()\n",
    "    # Update G\n",
    "    optimizerG.step()\n",
    "\n",
    "    return {\n",
    "        \"Loss_G\" : errG.item(),\n",
    "        \"Loss_D\" : errD.item(),\n",
    "        \"D_x\": output1.mean().item(),\n",
    "        \"D_G_z1\": output2.mean().item(),\n",
    "        \"D_G_z2\": output3.mean().item(),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8db0e36-f11a-47e1-bdb0-82c12e791329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the training_step function into Ignite Engine\n",
    "trainer = Engine(training_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8b7235-cfb3-45f4-8be5-3dff2b9f3a43",
   "metadata": {},
   "source": [
    "# Handlers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab410de-104c-4555-96b5-762cc1480bd6",
   "metadata": {},
   "source": [
    "### DC-GAN weights initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48369190-bbe6-44b9-a1c0-f6fc8a7fbbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_fn(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9a00f0-58b5-4ee7-b166-204482ba1082",
   "metadata": {},
   "outputs": [],
   "source": [
    "@trainer.on(Events.STARTED)\n",
    "def init_weights():\n",
    "    netD.apply(initialize_fn)\n",
    "    netG.apply(initialize_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78997ef3-dc73-4441-a286-538b85015993",
   "metadata": {},
   "source": [
    "### Losses storaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b41a31-f71f-4a5f-8ff4-6c4d0d73ad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_losses = []\n",
    "D_losses = []\n",
    "\n",
    "\n",
    "@trainer.on(Events.ITERATION_COMPLETED)\n",
    "def store_losses(engine):\n",
    "    o = engine.state.output\n",
    "    G_losses.append(o[\"Loss_G\"])\n",
    "    D_losses.append(o[\"Loss_D\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8a224b-89d6-4f94-9af5-5322b8bb2c7a",
   "metadata": {},
   "source": [
    "### Store images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466b289a-9421-4216-a8f8-be0b1934864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = []\n",
    "\n",
    "\n",
    "@trainer.on(Events.ITERATION_COMPLETED(every=500))\n",
    "def store_images(engine):\n",
    "    with torch.no_grad():\n",
    "        fake = netG(fixed_noise).cpu()\n",
    "    img_list.append(fake)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d3f45b-2e5d-4df5-8448-6aaa52c6b222",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d959c9bc-0ae5-4c2b-bfe2-619fe9ed5d7e",
   "metadata": {},
   "source": [
    "We will be using Inception Score (IS) and Frechet Inception Distance (FID) metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d52244d-b443-4060-892c-0702ee7c73de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_metric = FID(device=idist.device())\n",
    "is_metric = InceptionScore(device=idist.device(), output_transform=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eea7eca-193e-4661-9957-57f1703559fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Interpolate dataset images to 299x299x3 to be able to work with IS and FID prebuilt functions\n",
    "def interpolate(batch):\n",
    "    arr = []\n",
    "    for img in batch:\n",
    "        pil_img = transforms.ToPILImage()(img)\n",
    "        resized_img = pil_img.resize((299,299), Image.BILINEAR)\n",
    "        arr.append(transforms.ToTensor()(resized_img))\n",
    "    return torch.stack(arr)\n",
    "\n",
    "## Apply interpolation to fake and real batch images\n",
    "def evaluation_step(engine, batch):\n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn(batch_size, latent_dim, 1, 1, device=idist.device())\n",
    "        netG.eval()\n",
    "        fake_batch = netG(noise)\n",
    "        fake = interpolate(fake_batch)\n",
    "        real = interpolate(batch[0])\n",
    "        return fake, real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97527ebd-7bb3-4b67-82b7-ea1ac3743dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create evaluation Engine\n",
    "evaluator = Engine(evaluation_step)\n",
    "fid_metric.attach(evaluator, \"fid\")\n",
    "is_metric.attach(evaluator, \"is\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ef5bf7-8488-4c38-aeee-63e94db4e050",
   "metadata": {},
   "source": [
    "We define the evaluation handler per epoch for the trainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb52c51-78ad-4564-8d6d-715bc96148f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_values = []\n",
    "is_values = []\n",
    "\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(engine):\n",
    "    evaluator.run(test_dataloader,max_epochs=1)\n",
    "    metrics = evaluator.state.metrics\n",
    "    fid_score = metrics['fid']\n",
    "    is_score = metrics['is']\n",
    "    fid_values.append(fid_score)\n",
    "    is_values.append(is_score)\n",
    "    print(f\"Epoch [{engine.state.epoch}/5] Metric Scores\")\n",
    "    print(f\"*   FID : {fid_score:4f}\")\n",
    "    print(f\"*    IS : {is_score:4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372f4e77-a6a0-45d2-b75a-d1d9314a7e22",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889e3916-d435-4983-beb8-eb40ffddd5df",
   "metadata": {},
   "source": [
    "We define some progress bars for monitoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac394d2a-62f5-4cde-8fb6-655f46abc3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProgressBar().attach(trainer, metric_names=['Loss_G','Loss_D'])\n",
    "ProgressBar().attach(evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c57ef0d-a054-454e-99d3-ae7fe8301b68",
   "metadata": {},
   "source": [
    "Finally the training function that runs the iterative learning process on the trainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357ddcdd-313c-4069-9c15-9d5b7ab91a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(*args):\n",
    "    trainer.run(train_dataloader, max_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af75c304-24ac-4104-832c-e3c4d416895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with idist.Parallel(backend='nccl') as parallel:\n",
    "    parallel.run(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca25814-d2ef-438f-b963-6bedfd1b56c2",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054789eb-8a96-42f5-a8bc-49cda29038fa",
   "metadata": {},
   "source": [
    "### Loss per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd04034b-87a3-4b44-a888-60d0e95b40e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b779c612-cf4c-441f-ad6b-43e18c24e35a",
   "metadata": {},
   "source": [
    "### Evaluation Metrics per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a3cecc-fb6b-4919-a42e-25b6ab98505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "plt.title(\"Evaluation Metric During Training\")\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('epochs')\n",
    "ax1.set_ylabel('IS', color=color)\n",
    "ax1.plot(is_values, color=color)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('FID', color=color)\n",
    "ax2.plot(fid_values, color=color)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4072190-fdf4-44e5-9c7a-1776678bb4c8",
   "metadata": {},
   "source": [
    "### Real Images vs Fake Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519ca81d-840e-4dfd-a3ca-ee8949032be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Grab a batch of real images from the dataloader\n",
    "real_batch = next(iter(train_dataloader))\n",
    "\n",
    "# Plot the real images\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0][:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(img_list[-1], padding=2, normalize=True).cpu(),(1,2,0)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
